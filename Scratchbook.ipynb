{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Science Questions Scratchbook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpNOb3OdD_dC",
        "colab_type": "text"
      },
      "source": [
        "### Part 1. The data\n",
        "\n",
        "We'll use a Markov Chain model to build a sentence using words in the Science Questions dataset.\n",
        "\n",
        "Sentences are generated by picking a starting word and repeatedly choosing a random next word (based on transitions learned from the data) until a sentence is complete.\n",
        "\n",
        "For example if we had two questions such as *'What is love?'* and *'What the heck?'*, our model would say that **What** can be followed by either **is** or **love**.\n",
        "\n",
        "The goal for the data is to generate the transitions. We'll represent this output as ```dict```s, where ```key, value``` pairs are a word and list of next words, e.g.:\n",
        "\n",
        "```python\n",
        "{ 'What' : ['is', 'the'],\n",
        "  'is' : ['love'],\n",
        "  # and so on\n",
        "}\n",
        "```\n",
        "\n",
        "Markov chain [explainer](https://setosa.io/ev/markov-chains/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY-pst7HCKTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "from collections import defaultdict, Counter\n",
        "from itertools import accumulate\n",
        "import json\n",
        "import re\n",
        "from typing import List, DefaultDict\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxq0lBr1DVgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data path variables\n",
        "PATH = '/content/drive/My Drive/datasets/science_questions'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qB74eToDVqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the data\n",
        "with open(f'{PATH}/questions.csv') as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    raw_questions = [row['question'] for row in reader]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y-zTKd6DVs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "4edbf5ed-e3b3-442f-f312-2f2b10d9bce6"
      },
      "source": [
        "# Example output\n",
        "raw_questions[0:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Which property of an object is identified using the sense of smell? (A) color (B) odor (C) temperature (D) weight',\n",
              " 'Which type of energy is needed to cut a piece of wood into smaller pieces with a saw? (A) light (B) heat (C) sound (D) mechanical',\n",
              " 'Which material is the best conductor of electricity? (A) metal (B) glass (C) wood (D) plastic',\n",
              " 'What force causes objects to be pulled toward Earth? (A) friction (B) gravity (C) light (D) electricity',\n",
              " 'When a rock is placed in a graduated cylinder containing water, the height of the water will (A) decrease (B) increase (C) remain the same',\n",
              " 'Which energy transformation occurs when a person hits a drum with a drumstick? (A) electrical to light (B) sound to electrical (C) light to mechanical (D) mechanical to sound',\n",
              " 'A magnet and a metal paper clip have the strongest magnetic attraction when the distance between them is (A) 4 centimeters (B) 8 centimeters (C) 12 centimeters (D) 16 centimeters',\n",
              " 'A student rubs her hands together on a cold winter day. The heat that warms her hands is produced by (A) friction (B) gravity (C) light (D) magnetism',\n",
              " 'Which property of a rubber band will stay the same when it is stretched? (A) shape (B) length (C) mass (D) width',\n",
              " 'Precipitation is most likely to occur when the sky (A) is clear and sunny (B) is partly sunny (C) has thick, dark clouds (D) has white, puffy clouds']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3kuhm_cIQz8",
        "colab_type": "text"
      },
      "source": [
        "By looking at the data we'll want *two* Markov chain models since questions and answers look quite different from one another. \n",
        "\n",
        "We'll generate two sets:\n",
        "> 1. Question transitions\n",
        "2. Answer transitions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYErxhmeSWqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4fc7f59d-c67e-4255-c941-53b0c4128ce4"
      },
      "source": [
        "# Use regex to separate questions from answers\n",
        "# This looks for the letters A-D in parentheses, and splits the string where it finds them.\n",
        "# See notes below\n",
        "re.split(\"\\([A-D]\\)\", raw_questions[0])\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Which property of an object is identified using the sense of smell? ',\n",
              " ' color ',\n",
              " ' odor ',\n",
              " ' temperature ',\n",
              " ' weight']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YltNuX1aORMb",
        "colab_type": "text"
      },
      "source": [
        "**Regex notes**\n",
        ">```+```</br>\n",
        "Causes the resulting RE to match 1 or more repetitions of the preceding RE. ab+ will match ‘a’ followed by any non-zero number of ‘b’s; it will not match just ‘a’.\n",
        "\n",
        ">```[ ]``` </br>\n",
        "Used to indicate a set of characters. In a set: Characters can be listed individually, e.g. ```[amk]``` will match 'a', 'm', or 'k'. Ranges of characters can be indicated by giving two characters and separating them by a '-', for example ```[a-z]``` will match any lowercase ASCII letter, ```[0-5][0-9]``` will match all the two-digits numbers from 00 to 59, and ```[0-9A-Fa-f]``` will match any hexadecimal digit. If - is escaped (e.g. ```[a\\-z]```) or if it’s placed as the first or last character (e.g. ```[-a]``` or ```[a-]```), it will match a literal '\n",
        "\n",
        "\n",
        ">```\\``` </br>\n",
        "Either escapes special characters (permitting you to match characters like '*', '?', and so forth), or signals a special sequence; special sequences are discussed below.\n",
        "\n",
        ">```(...)``` </br>\n",
        "Matches whatever regular expression is inside the parentheses, and indicates the start and end of a group; the contents of a group can be retrieved after a match has been performed, and can be matched later in the string with the \\number special sequence, described below. To match the literals ```'('``` or ```')'```, use ```\\(``` or ```\\)```, or enclose them inside a character class: ```[(]```, ```[)]```.\n",
        "\n",
        "> ```\\s``` </br>\n",
        "For Unicode ```(str)``` patterns:\n",
        "Matches Unicode whitespace characters (which includes ```[ \\t\\n\\r\\f\\v]```, and also many other characters, for example the non-breaking spaces mandated by typography rules in many languages). If the ASCII flag is used, only ```[ \\t\\n\\r\\f\\v]``` is matched.\n",
        "\n",
        "</br>\n",
        "\n",
        "Looking at the questions data, every question has 3 to 4 answers, so the result of the split should have 4 to 5 elements (including the questions text).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSafJCYMTSgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "377bc2e9-1c55-4b89-bb28-53b245a3c9f2"
      },
      "source": [
        "# Check if any of the questions does not fall into the above reasoning\n",
        "pattern = \"\\([A-D]\\)\"\n",
        "\n",
        "for q in raw_questions:\n",
        "    if len(re.split(pattern, q)) not in [4, 5]:\n",
        "        print(q)\n",
        "        break"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The floor of Lucy's classroom is in the shape of a rectangle. It is 20 yards long and its area is 180 square yards. What is the width of Lucy's classroom? A. 9 yards B. 18 yards C. 50 yards D. 70 yards\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5A3Z9eWJeoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build regex cases iteratively to cover all the questions\n",
        "splits = [\n",
        "  \"\\([A-D]\\)\",    # (A) python (B) haskell (C) javascript (D) ruby\n",
        "  \"\\s[A-D]\\.\\s\",  #  A. python  B. haskell  C. javascript  D. ruby\n",
        "  \"\\s[1-4]\\.\\s\",  #  1. python  2. haskell  3. javascript  4. ruby\n",
        "  \"\\s[A-D]\\s\",    #  A  python  B  haskell  C  javascript  D  ruby\n",
        "  \"\\s[FGHJ]\\s\",   #  F  python  G  haskell  H  javascript  J  ruby\n",
        "  \"\\n [A-D]\\s\"    #   A python\n",
        "                  #   B haskell\n",
        "                  #   C javascript\n",
        "                  #   D ruby\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck4RyXh26Q1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialise sentinels\n",
        "START = \"__START__\"\n",
        "STOP = \"__STOP__\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NckRHO5p7Zhy",
        "colab_type": "text"
      },
      "source": [
        "Sentinels will be used to add a transition from ```START``` to the first word of every sentence, and a transition from the last-est word of every sentence to ```STOP```.\n",
        "\n",
        "Logic:\n",
        "\n",
        "```python\n",
        "word = random_word_after(START)\n",
        "while word != STOP:\n",
        "  yield word\n",
        "  word = random_word_after(word)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EJeBHlT7EHi",
        "colab_type": "text"
      },
      "source": [
        "The strategy is as follows:\n",
        "\n",
        "- Collect the question *sentences* and answer *sentences* separately\n",
        "- Use the sentences to generate transitions ```dict```s\n",
        "- Serialise teh transionts, so they cna be used in other programs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQDpkFDi75Lj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "23409a6d-9878-474a-c167-7f242047575d"
      },
      "source": [
        "# Collecting\n",
        "\n",
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for q in raw_questions:\n",
        "    for pattern in splits:\n",
        "        pieces = [x.strip() for x in re.split(pattern, q)]\n",
        "        # If we collected 4 to 5 pieces\n",
        "        if len(pieces) in [4, 5]:\n",
        "            # Add the first to the questions and the rest to the answers\n",
        "            questions.append(pieces[0])\n",
        "            answers.extend(pieces[1:])\n",
        "            # Move to the next questions\n",
        "            break\n",
        "    else:\n",
        "        # Executed only when the loop is not terminated by break\n",
        "        # This finds elements that the if does not catch\n",
        "        print(q)\n",
        "\n",
        "# More on for...else loops here\n",
        "# https://www.geeksforgeeks.org/using-else-conditional-statement-with-for-loop-in-python/\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tyrone taped a list of things to do on his mirror so he would not forget to do them. The list included the following tasks: \n",
            " \n",
            " • Turn off the water while brushing your teeth. \n",
            " • Turn off the lights when you leave a room. \n",
            " • Close the refrigerator door quickly. \n",
            " • Do not leave the outside doors open. \n",
            " • Only take as much food as you can eat. \n",
            "  \n",
            " Based on Tyrone’s list, what is he trying to accomplish by performing these tasks?\n",
            "After one minute, which item is most likely too hot to touch?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmSDhuHk-bwK",
        "colab_type": "text"
      },
      "source": [
        "With the list of **questions** and **answers** we can create the transitions ```dict```s:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVljyjpR9jyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Regex to match\n",
        "    - a period\n",
        "    - a comma\n",
        "    - a question mark\n",
        "    - a word containing non of the above or spaces\n",
        "\"\"\"\n",
        "regex = \"[^ ?\\.,]+|\\?|\\.|\\,\"\n",
        "\n",
        "\n",
        "def make_transitions(sentences: List[str]) -> DefaultDict[str, str]:\n",
        "    \"\"\"\n",
        "    Takes a list of sentences and:\n",
        "        - Splits the words in each sentence\n",
        "        - Enters each word as a dictionary key\n",
        "        - Appends subsequent words to a list for each key\n",
        "\n",
        "    Each word in a list appears with higher / lower frequency\n",
        "    according to how often is found in the sentences.\n",
        "\n",
        "    This allows random choice to chain the words with higher probability\n",
        "    to follow a prvious one as they have higher frequency on the list.\n",
        "    \"\"\"\n",
        "    transitions = defaultdict(list)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        words = [START] + re.findall(regex, sentence) + [STOP]\n",
        "        for prev_word, next_word in zip(words, words[1:]):\n",
        "            transitions[prev_word].append(next_word)\n",
        "    \n",
        "    return transitions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nrZNyQ1_-AK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make the transitions\n",
        "q_transitions = make_transitions(questions)\n",
        "a_transitions = make_transitions(answers)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjkgtiXgEw5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb8dfff1-536f-4bb7-922c-c86881e35092"
      },
      "source": [
        "# Inspect the first 5 starting words\n",
        "q_transitions['__START__'][0:5]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Which', 'Which', 'Which', 'What', 'When']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KVJoa9TAlYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sentence generators\n",
        "def next_word(transitions: DefaultDict[str, str], key:str) -> str:\n",
        "    \"\"\"\n",
        "    Picks a word from the list correspondy to key in the transitions dict.\n",
        "    \"\"\" \n",
        "    return random.choice(transitions.get(key, [STOP]))\n",
        "\n",
        "def markov_gen(transitions: DefaultDict[str, str]) -> str:\n",
        "    \"\"\"\n",
        "    Starting at the START sentinel, calls next_word to\n",
        "    pick the word to use as a key to build a sentence.\n",
        "\n",
        "    Continues until STOP is encountered.\n",
        "    \"\"\"\n",
        "    # Get the next word starting at the START sentinel\n",
        "    word = next_word(transitions, START)\n",
        "    # Continue until word == STOP sentinel\n",
        "    while word != STOP:\n",
        "      yield word\n",
        "      word = next_word(transitions, word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WldutPGAneE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba3380eb-06a5-438c-a2f5-068f4d4e4046"
      },
      "source": [
        "' '.join(markov_gen(q_transitions))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Crows are composed of humans ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj0DCKYSGsQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Svae transition as JSON\n",
        "with open('questions.json', 'w') as f:\n",
        "    f.write(json.dumps(q_transitions))\n",
        "\n",
        "with open('answers.json', 'w') as f:\n",
        "    f.write(json.dumps(a_transitions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTpNjiPWwBpk",
        "colab_type": "text"
      },
      "source": [
        "### Optimisation\n",
        "\n",
        " ~ - For each list of words:\n",
        "1. Count occurrence with Counter()\n",
        "2. Create set and set length of uniques\n",
        "3. Create empty array of len(set), with the specific constructor\n",
        "4. Based on len set assign words\n",
        "> e.g. if I have 10 unique words and counter has 20 of one, add two to the array\n",
        "5. Final array should represent weights scaled to the number of uniques\n",
        "> a random selection should have more or less probability based to what was found by counter in the data ~\n",
        "**Not needed**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM_5bvztwV8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compress_transitions(transitions):\n",
        "    compressed = {}\n",
        "    for token, next_tokens in transitions.items():\n",
        "        counts = Counter(next_tokens)\n",
        "        compressed[token] = list(zip(counts.keys(), accumulate(counts.values())))\n",
        "    return compressed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INy-tNJGhl4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('questions_compressed.json', 'w') as f:\n",
        "    f.write(json.dumps(compress_transitions(q_transitions)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxAoqxu7igF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try to optimise giving a frequencey to each word\n",
        "counts = Counter(q_transitions['__START__'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNAf1_gDiubq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5c377bf-ea8d-4d57-c9bb-426f88d4b398"
      },
      "source": [
        "totals = []\n",
        "for key, value in counts.items():\n",
        "    totals.append(value)\n",
        "\n",
        "number_of_words = sum(totals)\n",
        "\n",
        "number_of_words"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayq5WxCojZD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "480b5e43-a933-4035-bb3c-a64676d99fc6"
      },
      "source": [
        "uniques = set()\n",
        "for key, value in counts.items():\n",
        "    if key not in uniques:\n",
        "        uniques.add(key)\n",
        "\n",
        "len(uniques)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "229"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhCgiszLjovw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76f8fd73-3922-4826-934c-34203f83db93"
      },
      "source": [
        "uniques"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'13',\n",
              " '22',\n",
              " 'A',\n",
              " 'About',\n",
              " 'Above',\n",
              " 'Adaptation',\n",
              " 'Adaptations',\n",
              " 'After',\n",
              " 'Air',\n",
              " 'Alex',\n",
              " 'Algae',\n",
              " 'All',\n",
              " 'Although',\n",
              " 'Aluminum',\n",
              " 'An',\n",
              " 'Andy',\n",
              " 'Animal',\n",
              " 'Animals',\n",
              " 'Anita',\n",
              " 'Annette',\n",
              " 'Another',\n",
              " 'Apple',\n",
              " 'Approximately',\n",
              " 'April',\n",
              " 'As',\n",
              " 'Ashley',\n",
              " 'At',\n",
              " 'Baby',\n",
              " 'Baking',\n",
              " 'Barry',\n",
              " 'Base',\n",
              " 'Based',\n",
              " 'Beans',\n",
              " 'Bears',\n",
              " 'Before',\n",
              " 'Benjamin',\n",
              " 'Beryl',\n",
              " 'Bill',\n",
              " 'Both',\n",
              " 'Butterflies',\n",
              " 'Cacti',\n",
              " 'Cameron',\n",
              " 'Camouflage',\n",
              " 'Carolina',\n",
              " 'Changes',\n",
              " 'Charlie',\n",
              " 'Chemical',\n",
              " 'Chris',\n",
              " 'Christy',\n",
              " 'Chromosomes',\n",
              " 'Clouds',\n",
              " 'Coal',\n",
              " 'Competition',\n",
              " 'Copper',\n",
              " 'Coral',\n",
              " 'Corals',\n",
              " 'Cows',\n",
              " 'Crows',\n",
              " 'Darker',\n",
              " 'David',\n",
              " 'Decomposers',\n",
              " 'Delilah',\n",
              " 'Derek',\n",
              " 'Different',\n",
              " 'Directions',\n",
              " 'Ducks',\n",
              " 'During',\n",
              " 'Early',\n",
              " 'Earth',\n",
              " 'Earthworms',\n",
              " 'Electricity',\n",
              " 'Elliot',\n",
              " 'Eric',\n",
              " 'Erin',\n",
              " 'Erosion',\n",
              " 'Eveline',\n",
              " 'Every',\n",
              " 'Everything',\n",
              " 'Eye',\n",
              " 'Farmers',\n",
              " 'Felicia',\n",
              " 'Females',\n",
              " 'Fifth',\n",
              " 'Flexibility',\n",
              " 'Food',\n",
              " 'For',\n",
              " 'Fossils',\n",
              " 'Four',\n",
              " 'Fourth',\n",
              " 'Francis',\n",
              " 'Frogs',\n",
              " 'From',\n",
              " 'Gary',\n",
              " 'Glaciers',\n",
              " 'Granite',\n",
              " 'Gravity',\n",
              " 'Green',\n",
              " 'Growing',\n",
              " 'Having',\n",
              " 'Hawks',\n",
              " 'Heat',\n",
              " 'Heating',\n",
              " 'Homes',\n",
              " 'How',\n",
              " 'Humans',\n",
              " 'Ice',\n",
              " 'If',\n",
              " 'In',\n",
              " 'It',\n",
              " 'Jake’s',\n",
              " 'Jennifer',\n",
              " 'Jessica',\n",
              " 'John',\n",
              " 'Jose',\n",
              " 'Julie',\n",
              " 'Kerry',\n",
              " 'Kira',\n",
              " 'Large',\n",
              " 'Like',\n",
              " 'Linda',\n",
              " 'Liquid',\n",
              " 'Lisa',\n",
              " 'Living',\n",
              " 'Louie',\n",
              " 'Making',\n",
              " 'Males',\n",
              " 'Many',\n",
              " 'Martha',\n",
              " 'Martina',\n",
              " 'Mary',\n",
              " 'Mason',\n",
              " 'Materials',\n",
              " 'Matt',\n",
              " 'Matter',\n",
              " 'Max',\n",
              " 'Micaela',\n",
              " 'Michael',\n",
              " 'Microorganisms',\n",
              " 'Mold',\n",
              " 'Monica',\n",
              " \"Monica's\",\n",
              " 'Moss',\n",
              " 'Most',\n",
              " 'Mountain',\n",
              " 'Moving',\n",
              " 'Muscles',\n",
              " 'Naomi',\n",
              " 'Natural',\n",
              " 'Nectar',\n",
              " 'Oak',\n",
              " 'On',\n",
              " 'One',\n",
              " 'Organisms',\n",
              " 'Organizations',\n",
              " 'Owen',\n",
              " 'Pat',\n",
              " 'Peach',\n",
              " 'People',\n",
              " 'Photosynthesis',\n",
              " 'Planets',\n",
              " 'Plants',\n",
              " 'Pollutants',\n",
              " 'Precipitation',\n",
              " 'Prehistoric',\n",
              " 'Puddles',\n",
              " 'Pumice',\n",
              " 'Question',\n",
              " 'Rabbits',\n",
              " 'Rachel',\n",
              " 'Rain',\n",
              " 'Respiration',\n",
              " 'Rocks',\n",
              " 'Roger',\n",
              " 'Salt',\n",
              " 'Sam',\n",
              " 'Sand',\n",
              " 'Sandra',\n",
              " 'Sandy',\n",
              " 'Scientists',\n",
              " 'Seeds',\n",
              " 'Selina',\n",
              " 'Several',\n",
              " 'Shale',\n",
              " 'Sharpening',\n",
              " 'Siblings',\n",
              " 'Since',\n",
              " 'Skunks',\n",
              " 'Skyler',\n",
              " 'Sleet',\n",
              " 'Small',\n",
              " 'Soil',\n",
              " 'Solar',\n",
              " 'Solids',\n",
              " 'Some',\n",
              " 'Sonar',\n",
              " 'Stars',\n",
              " 'Steel',\n",
              " 'Sterling',\n",
              " 'Structures',\n",
              " 'Students',\n",
              " 'Submarines',\n",
              " 'Television',\n",
              " 'Temperatures',\n",
              " 'The',\n",
              " 'There',\n",
              " 'Three',\n",
              " 'To',\n",
              " 'Tony',\n",
              " 'Trees',\n",
              " 'Trevor',\n",
              " 'Two',\n",
              " 'Tyrone',\n",
              " 'Units',\n",
              " 'Use',\n",
              " 'Vertical',\n",
              " 'Virtually',\n",
              " 'Volume',\n",
              " 'Water',\n",
              " 'Wayne',\n",
              " 'Weather',\n",
              " 'Weathering',\n",
              " 'What',\n",
              " 'When',\n",
              " 'Where',\n",
              " 'Which',\n",
              " 'While',\n",
              " 'Why',\n",
              " 'Wind',\n",
              " 'Windy'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}